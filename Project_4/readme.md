
# Architectural Basics #

## Image Normalization

## Number of Epochs and when to increase them

## we know our network is not going well, comparatively, very early

## Batch Size, and effects of batch size

## 3x3 Convolutions

## How many layers

## MaxPooling

## Receptive Field

## SoftMax

## Learning Rate

## 1x1 Convolutions

## Kernels and how do we decide the number of kernels?

## Batch Normalization

## Position of MaxPooling

## Concept of Transition Layers

## Position of Transition Layer

## The distance of MaxPooling from Prediction

## The distance of Batch Normalization from Prediction

## DropOut

## When do we introduce DropOut, or when do we know we have some overfitting

## When do we stop convolutions and go ahead with a larger kernel or some other alternative (which we have not yet covered)

## When to add validation checks

## LR schedule and concept behind it

## Adam vs SGD
